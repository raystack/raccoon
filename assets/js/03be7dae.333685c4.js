"use strict";(self.webpackChunkraccoon=self.webpackChunkraccoon||[]).push([[768],{5680:(e,n,o)=>{o.d(n,{xA:()=>u,yg:()=>d});var t=o(6540);function r(e,n,o){return n in e?Object.defineProperty(e,n,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[n]=o,e}function a(e,n){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),o.push.apply(o,t)}return o}function i(e){for(var n=1;n<arguments.length;n++){var o=null!=arguments[n]?arguments[n]:{};n%2?a(Object(o),!0).forEach((function(n){r(e,n,o[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):a(Object(o)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(o,n))}))}return e}function l(e,n){if(null==e)return{};var o,t,r=function(e,n){if(null==e)return{};var o,t,r={},a=Object.keys(e);for(t=0;t<a.length;t++)o=a[t],n.indexOf(o)>=0||(r[o]=e[o]);return r}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(t=0;t<a.length;t++)o=a[t],n.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(r[o]=e[o])}return r}var s=t.createContext({}),c=function(e){var n=t.useContext(s),o=n;return e&&(o="function"==typeof e?e(n):i(i({},n),e)),o},u=function(e){var n=c(e.components);return t.createElement(s.Provider,{value:n},e.children)},p="mdxType",g={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},h=t.forwardRef((function(e,n){var o=e.components,r=e.mdxType,a=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),p=c(o),h=r,d=p["".concat(s,".").concat(h)]||p[h]||g[h]||a;return o?t.createElement(d,i(i({ref:n},u),{},{components:o})):t.createElement(d,i({ref:n},u))}));function d(e,n){var o=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var a=o.length,i=new Array(a);i[0]=h;var l={};for(var s in n)hasOwnProperty.call(n,s)&&(l[s]=n[s]);l.originalType=e,l[p]="string"==typeof e?e:r,i[1]=l;for(var c=2;c<a;c++)i[c]=o[c];return t.createElement.apply(null,i)}return t.createElement.apply(null,o)}h.displayName="MDXCreateElement"},9868:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>s,contentTitle:()=>i,default:()=>g,frontMatter:()=>a,metadata:()=>l,toc:()=>c});var t=o(8168),r=(o(6540),o(5680));const a={toc_max_heading_level:4},i="Troubleshooting",l={unversionedId:"guides/troubleshooting",id:"guides/troubleshooting",title:"Troubleshooting",description:"Scale Up Racoon",source:"@site/docs/guides/troubleshooting.md",sourceDirName:"guides",slug:"/guides/troubleshooting",permalink:"/raccoon/guides/troubleshooting",draft:!1,editUrl:"https://github.com/raystack/raccoon/edit/master/docs/docs/guides/troubleshooting.md",tags:[],version:"current",frontMatter:{toc_max_heading_level:4},sidebar:"docsSidebar",previous:{title:"Monitoring",permalink:"/raccoon/guides/monitoring"},next:{title:"Architecture",permalink:"/raccoon/concepts/architecture"}},s={},c=[{value:"Scale Up Racoon",id:"scale-up-racoon",level:2},{value:"Server",id:"server",level:3},{value:"Worker",id:"worker",level:3},{value:"Publisher",id:"publisher",level:3},{value:"Kafka",id:"kafka",level:4},{value:"PubSub",id:"pubsub",level:4},{value:"Kinesis",id:"kinesis",level:4},{value:"Backpressure",id:"backpressure",level:2}],u={toc:c},p="wrapper";function g(e){let{components:n,...o}=e;return(0,r.yg)(p,(0,t.A)({},u,o,{components:n,mdxType:"MDXLayout"}),(0,r.yg)("h1",{id:"troubleshooting"},"Troubleshooting"),(0,r.yg)("h2",{id:"scale-up-racoon"},"Scale Up Racoon"),(0,r.yg)("p",null,"Internally, Raccoon has 3 main components that affect the capacity. The server, worker, and publisher. Each component has configurations that can be tune if necessary. Since those 3 components are forming a pipe, you need to make sure none of the components become a bottleneck."),(0,r.yg)("p",null,"To know the right configuration, you need to simulate with similar throughput as production. You can tune the configuration accordingly."),(0,r.yg)("p",null,"Following are details of what you can tune."),(0,r.yg)("h3",{id:"server"},"Server"),(0,r.yg)("p",null,"Raccoon is using WebSocket as a communication protocol from client to server. Websocket requires maintaining long-running connections. Each connection costs the OS an open file descriptor. When you reach the limit of the configured open file descriptor, the server won't be able to accept a new connection. By default, OS limit the number of the open file descriptor. You can look up how to increase the max open file descriptor. On Unix, you can do ",(0,r.yg)("inlineCode",{parentName:"p"},"ulimit -n")," to check max open file descriptor and ",(0,r.yg)("inlineCode",{parentName:"p"},"ulimit -n <number>")," to set a new limit."),(0,r.yg)("p",null,"Apart from OS configuration, there are configurations you can tune on Raccoon:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("a",{parentName:"li",href:"/raccoon/reference/configurations#server_websocket_max_conn"},"SERVER_WEBSOCKET_MAX_CONN")," To limit Raccoon resource utilization, we enforce a limit on WebSocket connection. The default value is 30000; adjust it if necessary.")),(0,r.yg)("h3",{id:"worker"},"Worker"),(0,r.yg)("p",null,"After the request is deserialized, the server puts the events on the buffer channel. The worker process events from the channel and publishes them downstream. You can think of the worker and the channel as a buffer in case the publisher slows down temporarily."),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("a",{parentName:"li",href:"/raccoon/reference/configurations#worker_buffer_channel_size"},"WORKER_BUFFER_CHANNEL_SIZE")," Buffer before the events get processed. The more the size, the longer it can tolerate a temporary spike or slow down."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("a",{parentName:"li",href:"/raccoon/reference/configurations#worker_pool_size"},"WORKER_POOL_SIZE")," The worker will call the publisher client and wait synchronously. Increase this according to the throughput.")),(0,r.yg)("h3",{id:"publisher"},"Publisher"),(0,r.yg)("p",null,"Raccoon has support for ",(0,r.yg)("inlineCode",{parentName:"p"},"kafka"),", ",(0,r.yg)("inlineCode",{parentName:"p"},"pubsub")," and ",(0,r.yg)("inlineCode",{parentName:"p"},"kinesis")," publishers."),(0,r.yg)("h4",{id:"kafka"},"Kafka"),(0,r.yg)("p",null,"Currently, Raccoon is using ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/confluentinc/confluent-kafka-go"},"Librd Kafka client Go wrapper")," as publisher client. There is plenty of guides out there to tune Kafka producer. Here are some configurations you can tune."),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("a",{parentName:"li",href:"https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md"},"PUBLISHER_KAFKA_CLIENT_BATCH_NUM_MESSAGES")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("a",{parentName:"li",href:"/raccoon/reference/configurations#publisher_kafka_client_acks"},"PUBLISHER_KAFKA_CLIENT_ACKS")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("a",{parentName:"li",href:"/raccoon/reference/configurations#publisher_kafka_client_"},"PUBLISHER","_","KAFKA","_","CLIENT_${conf}")," You can put any ",(0,r.yg)("a",{parentName:"li",href:"https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md"},"librd kafka configuration")," by replacing ",(0,r.yg)("inlineCode",{parentName:"li"},"${conf}")," with upper case'd configuration key and changing the delimiter to underscore. For example, to use ",(0,r.yg)("inlineCode",{parentName:"li"},"log.queue=true"),", you can set ",(0,r.yg)("inlineCode",{parentName:"li"},"PUBLISHER_KAFKA_CLIENT_LOG_QUEUE=true"))),(0,r.yg)("h4",{id:"pubsub"},"PubSub"),(0,r.yg)("p",null,"Raccoon uses ",(0,r.yg)("a",{parentName:"p",href:"https://pkg.go.dev/cloud.google.com/go/pubsub"},"cloud.google.com/go/pubsub")," as the producer client for publishing events to Google Cloud PubSub."),(0,r.yg)("p",null,"The default quota limits for writes are:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"4GiB/second for large regions"),(0,r.yg)("li",{parentName:"ul"},"800MiB/second for medium regions"),(0,r.yg)("li",{parentName:"ul"},"200MiB/second for small regions")),(0,r.yg)("p",null,"A single message (event) must not be bigger 10MiB. Although this limit can be increased by submitting a quota increase request."),(0,r.yg)("p",null,"Since PubSub is a managed service, you generally only need to worry about hitting quotas or rate limits. Refer to ",(0,r.yg)("a",{parentName:"p",href:"https://cloud.google.com/pubsub/quotas"},"PubSub documentation")," for more information. "),(0,r.yg)("h4",{id:"kinesis"},"Kinesis"),(0,r.yg)("p",null,"Raccoon uses ",(0,r.yg)("a",{parentName:"p",href:"https://pkg.go.dev/github.com/aws/aws-sdk-go-v2/service/kinesis"},"github.com/aws/aws-sdk-go-v2/service/kinesis")," as the producer client for publishing events to AWS Kinesis."),(0,r.yg)("p",null,"AWS Kinesis Data Stream come into two modes:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"Provisioned"),(0,r.yg)("li",{parentName:"ul"},"On-Demand")),(0,r.yg)("p",null,"With Provisioned mode, your throughput is computed using the formlua:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},"Throughput/Second = Number of Shards * 1MiB\nRecords/Second = Number of Shards * 1000\n")),(0,r.yg)("p",null,"Shards are the basic unit of capacity in Kinesis. Make sure to create enough shards to accomodate your expected throughtput."),(0,r.yg)("p",null,"With On-Demand mode, the capcity of your stream updates dynamically depending on demand. The lower bound for writes is 4 MiB/second with an upper bound of 200MiB/second. You can request an increase of this quota up to 2 GiB/second by submitting a support request."),(0,r.yg)("p",null,"A single message (event) must not exceed 1MiB in size. This is a hard limit and you cannot request an increase."),(0,r.yg)("p",null,"see ",(0,r.yg)("a",{parentName:"p",href:"https://docs.aws.amazon.com/streams/latest/dev/service-sizes-and-limits.html"},"AWS Kinesis documentation")," for more information."),(0,r.yg)("h2",{id:"backpressure"},"Backpressure"),(0,r.yg)("p",null,"You might see the ",(0,r.yg)("inlineCode",{parentName:"p"},"event_processing_duration_milliseconds")," keeps on increasing and ",(0,r.yg)("inlineCode",{parentName:"p"},"batch_idle_in_channel_milliseconds")," is in constant high value. In that case, Raccoon might get back-pressure from the publisher. If that happens, you can check the publisher, or you need to tune the publisher configuration on Raccoon."))}g.isMDXComponent=!0}}]);